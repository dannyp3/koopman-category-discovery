{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b1cac6-e646-44b8-8a27-d4e5757b3333",
   "metadata": {},
   "source": [
    "## Testing Category Discovery Using KCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e614314-6ccf-4ead-913a-5df891908447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from kcm.koopman_category_model import KoopmanCategoryModel\n",
    "from kcm.discovery import sup_con_loss, BaselineModel, HASHHead, cluster_acc, split_cluster_acc_v1, split_cluster_acc_v2, create_hash_ids\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "915ce3bb-b36c-4efe-a1b4-aeded7d249fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in at C:\\Users\\dbpet\\Documents\\JHU\\EN.625.801-802\\koopman-category-discovery\\data\\1-dimensional-systems\\dataset_4_class_100_noisy_samples.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/2) * 300^2 = 45000 Wasserstein distance metrics: 100%|█████████████████████████████████████████| 300/300 [12:51<00:00,  2.57s/it]\n",
      "7 * 2400 = 16800 Wasserstein distance metrics: 100%|██████████████████████████████████████████████████| 7/7 [03:35<00:00, 30.80s/it]\n",
      "7 * 1600 = 11200 Wasserstein distance metrics: 100%|██████████████████████████████████████████████████| 7/7 [02:33<00:00, 21.90s/it]\n"
     ]
    }
   ],
   "source": [
    "num_cats = 4\n",
    "num_samples = 100\n",
    "system_dimension = 1\n",
    "delay_embeddings = 3\n",
    "num_segments = 10\n",
    "svd_rank = None\n",
    "dmd_rank = None\n",
    "q = 2\n",
    "num_clusters = 7\n",
    "test_size = 0.2\n",
    "codebook_training_size = 300 # divides <num training classes> * num_segments \n",
    "category_discovery=True\n",
    "train_classes = [0,1,2]\n",
    "seed = 42\n",
    "\n",
    "KCM = KoopmanCategoryModel(num_cats=num_cats,\n",
    "                           num_samples=num_samples,\n",
    "                           system_dimension=system_dimension,\n",
    "                           delay_embeddings=delay_embeddings,\n",
    "                           num_segments=num_segments,\n",
    "                           svd_rank=svd_rank,\n",
    "                           dmd_rank=dmd_rank,\n",
    "                           q=q,\n",
    "                           cluster_method='kmeans',\n",
    "                           num_clusters=num_clusters,\n",
    "                           seed=seed)\n",
    "\n",
    "KCM.generate_data()\n",
    "KCM.train_test_split(test_size=test_size,\n",
    "                     codebook_training_size=codebook_training_size,\n",
    "                     category_discovery=category_discovery,\n",
    "                     train_classes=train_classes)\n",
    "KCM.create_codebook(include_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "895b109a-152a-4095-989b-dec76df46fda",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'kcm.koopman_category_model.KoopmanCategoryModel'>: it's not the same object as kcm.koopman_category_model.KoopmanCategoryModel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[253], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mKCM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m KCM\u001b[38;5;241m.\u001b[39mshutdown_logger()\n",
      "File \u001b[1;32m~\\Documents\\JHU\\EN.625.801-802\\koopman-category-discovery\\src\\kcm\\koopman_category_model.py:478\u001b[0m, in \u001b[0;36mKoopmanCategoryModel.save\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save *this* model object to <run_dir>/<name>.\"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_dir \u001b[38;5;241m/\u001b[39m name\n\u001b[1;32m--> 478\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, path)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\site-packages\\joblib\\numpy_pickle.py:553\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 553\u001b[0m         \u001b[43mNumpyPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     NumpyPickler(filename, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:687\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs[0] from __newobj__ args has the wrong class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    686\u001b[0m args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 687\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m save(args)\n\u001b[0;32m    689\u001b[0m write(NEWOBJ)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:1129\u001b[0m, in \u001b[0;36m_Pickler.save_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m):\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_reduce(\u001b[38;5;28mtype\u001b[39m, (\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,), obj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m-> 1129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\koopman\\lib\\pickle.py:1076\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj:\n\u001b[1;32m-> 1076\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1077\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms not the same object as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1078\u001b[0m             (obj, module_name, name))\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1081\u001b[0m     code \u001b[38;5;241m=\u001b[39m _extension_registry\u001b[38;5;241m.\u001b[39mget((module_name, name))\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'kcm.koopman_category_model.KoopmanCategoryModel'>: it's not the same object as kcm.koopman_category_model.KoopmanCategoryModel"
     ]
    }
   ],
   "source": [
    "KCM.save()\n",
    "KCM.shutdown_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "977602ef-83c4-417a-b798-3a294afd68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = KCM.inv_c_train_matrix\n",
    "y_train = KCM.train_target\n",
    "\n",
    "X_test = KCM.inv_c_test_matrix\n",
    "y_test = KCM.test_target\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.tensor(y_train).long().squeeze()\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.tensor(y_test).long().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1865072d-b2e3-4198-ba41-1cbcd1d3f739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique() # 80, 0, 80, 80 = 240 training samples (5 segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "42803d14-c609-48f7-a97c-4e366de74403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique() # 20, 100, 20, 20 = 160 testing samples (5 segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c35924f2-abcc-46bb-b04d-66eef2a69c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograms with Duplicate Labels:\n",
      "\n",
      "[0.    0.096 0.    0.    0.229 0.    0.   ] has 2 instances with [1 2] unique_labels\n",
      "[0.    0.161 0.    0.    0.164 0.    0.   ] has 13 instances with [1 2] unique_labels\n",
      "[0.    0.193 0.    0.    0.131 0.    0.   ] has 13 instances with [1 2] unique_labels\n",
      "[0.    0.225 0.    0.    0.098 0.    0.   ] has 20 instances with [1 2] unique_labels\n",
      "[0.    0.257 0.    0.    0.065 0.    0.   ] has 10 instances with [1 2] unique_labels\n",
      "[0.    0.289 0.    0.    0.033 0.    0.   ] has 5 instances with [1 2] unique_labels\n",
      "[0.118 0.096 0.    0.    0.196 0.    0.   ] has 2 instances with [1 2] unique_labels\n",
      "[0.118 0.161 0.    0.    0.131 0.    0.   ] has 6 instances with [1 2] unique_labels\n",
      "\n",
      "8/127 (6.3 %) of histograms had duplicate labels,\n",
      "\taffecting 71/400 samples (17.75 %)\n"
     ]
    }
   ],
   "source": [
    "unique_histograms, indices = torch.unique(X_train, dim=0, return_inverse=True)\n",
    "\n",
    "print('Histograms with Duplicate Labels:\\n')\n",
    "num_issue_hists = 0\n",
    "num_issue_samples = 0\n",
    "for uni, ind in zip(unique_histograms,torch.unique(indices)):\n",
    "\n",
    "    histogram_count = X_train[indices == ind].shape[0]\n",
    "    unique_labels = torch.unique(y_train[indices == ind])\n",
    "\n",
    "    if len(unique_labels) > 1:\n",
    "        num_issue_hists += 1\n",
    "        num_issue_samples += histogram_count\n",
    "        print(f'{np.round(np.array(uni),3)} has {histogram_count} instances with {np.array(unique_labels)} unique_labels')\n",
    "\n",
    "\n",
    "percent_hist_issues = round(num_issue_hists*100/len(unique_histograms),2)\n",
    "print(f'\\n{num_issue_hists}/{len(unique_histograms)} ({percent_hist_issues} %) of histograms had duplicate labels,')\n",
    "perc_sample_issues = round(num_issue_samples*100/(KCM.num_cats*KCM.num_samples),2)\n",
    "print(f'\\taffecting {num_issue_samples}/{KCM.num_cats*KCM.num_samples} samples ({perc_sample_issues} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e23396-b406-45a2-9526-ae2d2dc7a201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  90%|████████████████████████████████████████████████████████████████████▎       | 899/1000 [01:00<00:06, 15.05it/s]"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = 8\n",
    "hidden_dims = [200, 200] # [1024, 512, 256]\n",
    "dropout = 0.3\n",
    "classes = KCM.num_cats\n",
    "test_size = 0.25\n",
    "epochs = 1000\n",
    "model_type = 'SMILE' # baseline, SMILE\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    model = BaselineModel(input_dim, output_dim, hidden_dims, dropout)\n",
    "elif model_type == 'SMILE':\n",
    "    model = HASHHead(input_dim, output_dim, hidden_dims, dropout)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "true_y = KCM.df_test[['target','sample']].drop_duplicates()['target'].values\n",
    "mask = np.isin(true_y,KCM.train_classes)\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "train_aris = []\n",
    "train_nmis = []\n",
    "train_amis = []\n",
    "\n",
    "test_aris = []\n",
    "test_nmis = []\n",
    "test_amis = []\n",
    "\n",
    "weighted_scores = []\n",
    "old_scores = []\n",
    "new_scores = []\n",
    "\n",
    "global_scores = []\n",
    "old_global_scores = []\n",
    "new_global_scores = []\n",
    "\n",
    "unique_training_hashes = []\n",
    "unique_testing_hashes = []\n",
    "\n",
    "losses = []\n",
    "for i in tqdm(range(epochs), desc='Training Model'):\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        training_features, _, _ = model(X_train)\n",
    "        testing_features, _, _ = model(X_test)\n",
    "        sc_loss = sup_con_loss(training_features, y_train, temp=0.2)\n",
    "        reg_loss = 0\n",
    "        \n",
    "    elif model_type == 'SMILE':\n",
    "        training_features, training_hash_features, _ = model(X_train)\n",
    "        testing_features, testing_hash_features, _ = model(X_test)\n",
    "        sc_loss = sup_con_loss(training_features, y_train, temp=0.2)\n",
    "\n",
    "        reg_loss = (1 - torch.abs(training_hash_features)).mean()\n",
    "        \n",
    "\n",
    "    loss = sc_loss * 1 + reg_loss * 3\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Create Cluster ids for train, test, and full data sets\n",
    "    training_hash_ids, training_hashes, new_training_labels = create_hash_ids(training_features, y_train)\n",
    "    testing_hash_ids, testing_hashes, new_testing_labels = create_hash_ids(testing_features, y_test)\n",
    "    \n",
    "    # # Full dataset clusters\n",
    "    # features, _, _ = model(X)\n",
    "    # full_has_ids, full_hashes, new_full_labels = create_hash_ids(features, y)\n",
    "    \n",
    "    # Report ARI, NMI, and AMI for training and testing splits\n",
    "    train_aris.append(adjusted_rand_score(y_train, training_hash_ids))\n",
    "    train_nmis.append(normalized_mutual_info_score(y_train, training_hash_ids))\n",
    "    train_amis.append(adjusted_mutual_info_score(y_train, training_hash_ids))\n",
    "\n",
    "    test_aris.append(adjusted_rand_score(y_test, testing_hash_ids))\n",
    "    test_nmis.append(normalized_mutual_info_score(y_test, testing_hash_ids))\n",
    "    test_amis.append(adjusted_mutual_info_score(y_test, testing_hash_ids))\n",
    "\n",
    "    # Report category discovery metrics\n",
    "    total_acc, old_acc, new_acc = split_cluster_acc_v1(np.array(y_test), testing_hash_ids, mask)\n",
    "    weighted_scores.append(total_acc)\n",
    "    old_scores.append(old_acc)\n",
    "    new_scores.append(new_acc)\n",
    "    \n",
    "    total_acc, old_acc, new_acc = split_cluster_acc_v2(np.array(y_test), testing_hash_ids, mask)\n",
    "    global_scores.append(total_acc)\n",
    "    old_global_scores.append(old_acc)\n",
    "    new_global_scores.append(new_acc)\n",
    "\n",
    "    unique_training_hashes.append(len(np.unique(training_hash_ids)))\n",
    "    unique_testing_hashes.append(len(np.unique(testing_hash_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16d870-5986-4967-9720-da83ea9192eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(np.log(np.array(losses)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Supervised Contrastive Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363941b9-932f-4e2c-9754-6be25ff16fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "plt.plot(unique_training_hashes,label='Training')\n",
    "plt.plot(unique_testing_hashes,label='Testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Unique Hashes')\n",
    "plt.title('Number of Unique Hashes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac0775-fe8f-4847-9c87-8c1dc28510fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = plt.subplots(1,3,figsize=(12,3))\n",
    "\n",
    "minimum = -0.05\n",
    "maximum = 1.05\n",
    "\n",
    "# Plot independent & weighted scores\n",
    "axes[0].plot(old_scores,linewidth=0.8,color='blue',label='Old Classes')\n",
    "axes[0].plot(new_scores,linewidth=0.8,color='red',label='New Classes')\n",
    "axes[0].plot(weighted_scores,linewidth=2,color='purple',label='Total')\n",
    "axes[0].set_title('Independent Scores')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_ylim([minimum, maximum])\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot global scores\n",
    "axes[1].plot(old_global_scores,linewidth=0.8,color='blue',label='Old Classes')\n",
    "axes[1].plot(new_global_scores,linewidth=0.8,color='red',label='New Classes')\n",
    "axes[1].plot(global_scores,linewidth=2,color='purple',label='Total')\n",
    "axes[1].set_title('Global Scores')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylim([minimum, maximum])\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot training and testing aris\n",
    "axes[2].plot(train_aris,linewidth=2,color='lightblue',label='Train ARI')\n",
    "axes[2].plot(train_nmis,linewidth=1,color='mediumblue',label='Train NMI')\n",
    "axes[2].plot(train_amis,linewidth=0.5,color='darkblue',label='Train AMI')\n",
    "axes[2].plot(test_aris,linewidth=2,color='lightcoral',label='Test ARI')\n",
    "axes[2].plot(test_nmis,linewidth=1,color='red',label='Test NMI')\n",
    "axes[2].plot(test_amis,linewidth=0.5,color='darkred',label='Test AMI')\n",
    "axes[2].set_title('')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylim([minimum, maximum])\n",
    "axes[2].legend()\n",
    "\n",
    "\n",
    "plt.suptitle('Category Discovery Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe47363-f018-4f00-8772-9fd859946c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics (means, variances, angular momentums, periodicity, etc.) - to construct a feature vector for comparison\n",
    "\n",
    "# Try introducing noise to see how koopman feature extractor compares with other methods - statistical methods will suffer big time with noise\n",
    "# Comparing with random features for comparison to random\n",
    "\n",
    "# Play around with the size of the encoder (more parameters than features?)\n",
    "# Try making num_parameters < num_data inputs (maybe ~20%) - make only 2 layers with smaller hidden dimensions\n",
    "\n",
    "# Change size of hash vector\n",
    "\n",
    "# How to augment the dataset for optimized category discovery - add more categories\n",
    "# Can training on more classes help discover more categories?\n",
    "# Test out changing training and testing class sizes\n",
    "# Compare train on 1-3 and discover 3-1\n",
    "\n",
    "# Send some basic figures to Cetin and Charlie\n",
    "\n",
    "\n",
    "# Observations\n",
    "\n",
    "# With a smaller neural network, it just bunches a lot of the samples into the same categories, particulary the non-harmonic ones\n",
    "# The network has higher accuracy at the very beginning - this could be due to the repetitive nature of the histograms from KCM\n",
    "# There are some histogram values that are repeated across different systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6ad91-ab3b-4718-bcde-6059db8df862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df,combine=True,y_to_color=None,all_y_vals=None):\n",
    "\n",
    "    all_clusters = sorted(df['cluster_id'].unique())\n",
    "    unique_y = sorted(df['y'].unique()) if all_y_vals is None else sorted(all_y_vals)\n",
    "    \n",
    "    x = np.arange(len(all_clusters))\n",
    "    width = 0.8 / len(unique_y)\n",
    "\n",
    "    if y_to_color is None:\n",
    "        cmap = plt.get_cmap('tab10')\n",
    "        y_to_color = {y: cmap(i % 10) for i, y in enumerate(unique_y)}\n",
    "        \n",
    "\n",
    "    if combine:\n",
    "        plt.figure(figsize=(8,3))\n",
    "        for i, y_val in enumerate(unique_y):\n",
    "            counts = df.loc[df['y'].eq(y_val),'cluster_id'].value_counts().reindex(all_clusters, fill_value=0)\n",
    "            pmf = counts / counts.sum()\n",
    "            bar_positions = x + i * width\n",
    "            plt.bar(bar_positions, pmf, width=width, label=f'y = {y_val}', color=y_to_color.get(y_val, 'gray'))\n",
    "        \n",
    "        plt.xlabel('cluster_id')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Cluster ID Value Counts by y')\n",
    "        plt.xticks(x + width * (len(unique_y) - 1) / 2, labels=all_clusters)\n",
    "        plt.legend(title='y value')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(unique_y), 1, figsize=(6, 10), constrained_layout=True)\n",
    "        for i, y_val in enumerate(unique_y):\n",
    "            counts = train.loc[train['y'].eq(y_val),'cluster_id'].value_counts().reindex(all_clusters, fill_value=0)\n",
    "            pmf = counts / counts.sum()\n",
    "            axs[i].bar(all_clusters, pmf, color=y_to_color.get(y_val, 'gray'))\n",
    "            axs[i].set_title(f'Histogram of cluster_ids for y = {y_val}')\n",
    "            axs[i].set_xlabel('cluster_id')\n",
    "            axs[i].set_ylabel('Frequency')\n",
    "            axs[i].set_xticks(all_clusters)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737efec-b441-4e9e-8b7b-a3a7f12cf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'cluster_id' : training_cluster_ids, 'y' : y_train}\n",
    "data = {'cluster_id' : training_hash_ids, 'y' : y_train}\n",
    "train = pd.DataFrame(data)\n",
    "\n",
    "# data = {'cluster_id' : testing_cluster_ids, 'y' : y_test}\n",
    "data = {'cluster_id' : testing_hash_ids, 'y' : y_test}\n",
    "test = pd.DataFrame(data)\n",
    "\n",
    "for i in range(output_dim):\n",
    "    train[f'hash_{i}'] = training_hashes[:,i]\n",
    "    test[f'hash_{i}'] = testing_hashes[:,i]\n",
    "\n",
    "all_y_vals = sorted(set(train['y']).union(set(test['y'])))\n",
    "\n",
    "# Create consistent color mapping\n",
    "cmap = plt.get_cmap('tab10')\n",
    "y_to_color = {y: cmap(i % 10) for i, y in enumerate(all_y_vals)}\n",
    "\n",
    "\n",
    "plot_histograms(train,combine=True,y_to_color=y_to_color)\n",
    "plot_histograms(test,combine=True,y_to_color=y_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7d499-3e70-47f3-a325-d4127f0d7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0,1,0,1,0,1,0,1]\n",
    "# [1,1,1,1,0,0,0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
